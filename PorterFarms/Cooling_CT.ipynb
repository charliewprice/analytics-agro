{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooling Equipment Monitoring\n",
    "\n",
    "This monitor script is used where CTs are used on circuits activated when a __room temperature exceeds a threshold value__ then deactivated when room temperature falls below the threshold value.<br>\n",
    "\n",
    "The following issues are used in tickets opened by this script:\n",
    "- CODE_RED\n",
    "- CODE_ORANGE\n",
    "- CODE_BLUE\n",
    "\n",
    "### CODE_RED LOW_CURRENT_ABOVE_TCRIT<br>\n",
    "This issue can arise if a circuit breaker has tripped, equipment is unplugged, drive belts are broken, or the equipment has failed open-circuit.  This is __CRITICAL__ as is is indicative of __LOW__ or __NO AIR MOVEMENT__.\n",
    "### CODE_ORANGE HIGH_CURRENT_ABOVE_TCRIT<br>\n",
    "This issue can arise if equipment is under excessive load caused by bearing degradation, blocked air streams, or if the equipment has failed closed-circuit.  This issue can be __CRITICAL__ or __WARNING__. \n",
    "### CODE_BLUE HIGH_CURRENT_BELOW_TCRIT<br>\n",
    "This issue may occur if the switching device has failed in the __ON__ mode. This issue may be __CRITICAL__ when the room temperature is extremely low.<br>\n",
    "\n",
    "This script currently uses fixed TCRIT and IDLEBAND settings.  Enhancements may be included at some point to calculate these parameters based on scatter diagram histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mote Types having the CT Sensors\n",
    "CT_PROFILER_MOTE = 10003\n",
    "DEPLOYED_ACTIVE  = 10001\n",
    "\n",
    "#Ticket Types\n",
    "CODE_GREEN  = 11000  # normally not ticketed\n",
    "CODE_RED    = 11001\n",
    "CODE_ORANGE = 11002\n",
    "CODE_BLUE   = 11003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "/  Cooling_CT is running.                  /\n",
      "============================================\n",
      "/home/sensei/jupy-notebooks/Analytics/PorterFarms\n",
      "Python version\n",
      "3.7.2 (default, Dec 29 2018, 06:19:36) \n",
      "[GCC 7.3.0]\n",
      "Version info.\n",
      "sys.version_info(major=3, minor=7, micro=2, releaselevel='final', serial=0)\n",
      "Welcome to Jupyter Notebook.  You are connected to the Kanji database!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/sensei/jupy-notebooks/Analytics/PorterFarms')\n",
    "print(\"============================================\")\n",
    "print(\"/  Cooling_CT is running.                  /\")\n",
    "print(\"============================================\")\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from slackclient import SlackClient\n",
    "import json\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import time\n",
    "\n",
    "print(os.getcwd())\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"../../analytics_secrets.ini\")\n",
    "\n",
    "_ACTIVE_STANDBY = config['DEFAULT']['role']\n",
    "if _ACTIVE_STANDBY == 'STANDBY':\n",
    "    print(\"STANDBY\")\n",
    "    raise SystemExit(\"Stop right there!\")\n",
    "else:\n",
    "  _SLACK_TOKEN = config['slack']['token']\n",
    "  _CHIRPSTACK_USER = config['chirpstack']['user']\n",
    "  _CHIRPSTACK_PASS = config['chirpstack']['password']\n",
    "  _DB_HOST  = config['kanjidb']['dbhost']\n",
    "  _DB_PORT  = config['kanjidb']['dbport']\n",
    "  _DB_NAME  = config['kanjidb']['dbname']\n",
    "  _DB_USER  = config['kanjidb']['dbuser']\n",
    "  _DB_PASS  = config['kanjidb']['dbpass']\n",
    "    \n",
    "  _LOG_DEBUG = 0\n",
    "  _LOG_INFO  = 1\n",
    "  _LOG_ERROR = 2\n",
    "  _LOG_LEVEL = int(config['DEFAULT']['loglevel'])\n",
    "      \n",
    "def logger(level, message):\n",
    "    if level >= _LOG_LEVEL:\n",
    "      print(message)\n",
    "\n",
    "logger(_LOG_DEBUG, \"{} {} {} {} {}\".format(_DB_HOST, _DB_PORT, _DB_NAME, _DB_USER, _DB_PASS))\n",
    "\n",
    "import kanjiticketing as kt\n",
    "\n",
    "conn = kt.getKanjiDbConnection(_DB_HOST, _DB_PORT, _DB_NAME, _DB_USER, _DB_PASS)\n",
    "if conn is not None:\n",
    "  print(\"Welcome to Jupyter Notebook.  You are connected to the Kanji database!\")\n",
    "else:\n",
    "  print(\"You are not connected to the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticketIssue(conn, node_id, ticket_type, description):\n",
    "  openTicket = kt.ticketExists(conn, node_id, ticket_type, [kt._OPEN_STATUS, kt._WORKING_STATUS])\n",
    "  if openTicket is None:\n",
    "    query = \"SELECT    node.name, node.location_id, location.description, location.slackalertchannel_id, \\\n",
    "                       location.imageurl, customer.slacktoken, slackchannel.idslackchannel, slackchannel.channelid \\\n",
    "                       FROM kanji_node node JOIN kanji_location location ON location.idlocation=node.location_id \\\n",
    "                       JOIN kanji_slackchannel slackchannel ON location.slackalertchannel_id=slackchannel.idslackchannel \\\n",
    "                       JOIN kanji_customer customer ON customer.idcustomer=node.customer_id \\\n",
    "                       WHERE node.idnode={}\".format(node_id)\n",
    "    logger(_LOG_INFO, query)\n",
    "    df = pd.read_sql(query, conn)    \n",
    "    locationid = df['location_id'][0]\n",
    "    locationdescription = df['description'][0]\n",
    "    alerttextquery = \"SELECT alerttext FROM kanji_tickettype WHERE idtickettype={}\".format(ticket_type)\n",
    "    df2 = pd.read_sql(alerttextquery, conn)\n",
    "    ticketdescription = description + \" \" + df2['alerttext'][0]\n",
    "    slackchannelid = df['idslackchannel'][0]\n",
    "    slackchannelname = df['channelid'][0]\n",
    "    nodename = df['name'][0]\n",
    "    mentions = \"@Charlie\"\n",
    "    locationimageurl = df['imageurl'][0]\n",
    "    slacktoken = df['slacktoken'][0]\n",
    "    \n",
    "    logger(_LOG_DEBUG,\"channel={} token={}\".format(slackchannelid,slacktoken))\n",
    "    \n",
    "    ticketid = kt.openticket(conn, node_id, locationid, ticketdescription, 2, 3, ticket_type, slackchannelid)\n",
    "    ts = kt.slackticket(nodename, locationdescription, ticketdescription, mentions, 2, 3, locationimageurl, \\\n",
    "                        slacktoken,slackchannelname, ticketid, 0)\n",
    "    kt.updateTicket(conn, ticketid, ts)  \n",
    "    logger(_LOG_INFO, \"New ticket {} created for this issue.\".format(ticketid))\n",
    "  else:\n",
    "    logger(_LOG_INFO, \"There is an existing ticket {} for this issue. {}\".format(openTicket['idticket'][0], openTicket['opentimestamp'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messagetemplate = \"[\\\n",
    "   {\\\"type\\\": \\\"section\\\", \\\n",
    "\t\t\\\"text\\\": { \\\n",
    "\t\t\t\\\"type\\\": \\\"mrkdwn\\\", \\\n",
    "\t\t\t\\\"text\\\": \\\"*<fakeLink.toUserProfiles.com|Iris / Zelda 1-1>*\\\\nTuesday, January 21 4:00-4:30pm\\\\nBuilding 2 - Havarti Cheese (3)\\\\n2 guests\\\" \\\n",
    "\t\t}, \\\n",
    "\t\t\\\"accessory\\\": { \\\n",
    "\t\t\t\\\"type\\\": \\\"image\\\", \\\n",
    "\t\t\t\\\"image_url\\\": \\\"https://api.slack.com/img/blocks/bkb_template_images/notifications.png\\\", \\\n",
    "\t\t\t\\\"alt_text\\\": \\\"calendar thumbnail\\\" \\\n",
    "\t\t} \\\n",
    "   } ]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postMessageToSlack(text):    \n",
    "    sc = SlackClient(_SLACK_TOKEN)\n",
    "    slackchannel = \"infrastructure\"\n",
    "    response = sc.api_call(\"chat.postMessage\", channel=slackchannel, text=text, blocks=[])\n",
    "    if not 'ok' in response or not response['ok']:\n",
    "      print(\"Error posting message to Slack channel\")\n",
    "      print(response)\n",
    "    else:\n",
    "      print(\"Ok posting message to Slack channel\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterize(df):\n",
    "  _ICRIT   = 2.0\n",
    "  tempon   = 0.0\n",
    "  tempoff  = 0.0\n",
    "  temponmax    = 0.0\n",
    "  tempoffmin   = 120.0\n",
    "  counton  = 0\n",
    "  countoff = 0\n",
    "  lastamps = 0.0 \n",
    "  ampson = 0.0\n",
    "  ampsoff = 0.0\n",
    "  for ind in df.index:\n",
    "    thistemp = df['tempf'][ind]\n",
    "    thisamps = df['mesh_amps'][ind]\n",
    "    if (lastamps<_ICRIT) and (thisamps>=_ICRIT):\n",
    "      counton += 1\n",
    "      tempon  += thistemp\n",
    "      ampson  += thisamps\n",
    "      if thistemp>temponmax:\n",
    "        temponmax=thistemp\n",
    "    elif (lastamps>_ICRIT) and (thisamps<=_ICRIT):\n",
    "      countoff += 1\n",
    "      tempoff += thistemp\n",
    "      ampsoff += thisamps\n",
    "      if thistemp<tempoffmin:\n",
    "        tempoffmin=thistemp\n",
    "    lastamps = thisamps\n",
    "  if counton>0 and countoff>0:\n",
    "    dict = {'temponmax': temponmax, \n",
    "            'avgon': tempon/counton, \n",
    "            'tempoffmin': tempoffmin, \n",
    "            'avgoff': tempoff/countoff,\n",
    "            'avgonamps' : ampson/counton,\n",
    "            'avgoffamps': ampsoff/countoff,\n",
    "            'setpoint': (tempoffmin+temponmax)/2,\n",
    "            'idleband': (temponmax-tempoffmin)/2,\n",
    "            'counton' : counton,\n",
    "            'countoff' : countoff}\n",
    "  else:\n",
    "    dict = {'temponmax': 80.0, \n",
    "            'avgon': 79.0, \n",
    "            'tempoffmin': 70.0, \n",
    "            'avgoff': 71.0,\n",
    "            'setpoint': 75.0,\n",
    "            'idleband': 2.0,\n",
    "            'avgonamps' : 10.0,\n",
    "            'avgoffamps': 0.0,\n",
    "            'counton' : 99,\n",
    "            'countoff' : 99}\n",
    "  #logger(_LOG_INFO,\"Inferred Thermostat Settings:\")  \n",
    "  #logger(_LOG_INFO, dict)\n",
    "  return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy\n",
    "Determine if circuit current is within the polygon on the current(T) plot\n",
    "\n",
    "Plot the polygon for reference\n",
    "Plot the latest value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Cooling data for Breeding agMote-20015\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT  timestamp,                        bval AS tempf,                        cval AS mesh_amps                        FROM kanji_eventlog WHERE node_id=20015 AND fcnt>0                        AND timestamp>NOW() - INTERVAL '18 HOURS'                        ORDER BY timestamp desc;': column \"bval\" does not exist\nLINE 1: SELECT  timestamp,                        bval AS tempf,    ...\n                                                  ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/KanjiBooks/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: column \"bval\" does not exist\nLINE 1: SELECT  timestamp,                        bval AS tempf,    ...\n                                                  ^\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-455e08c7c4b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m                        \u001b[0mORDER\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mtimestamp\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_COLUMNS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoteid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PERIOD_HOURS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LOG_DEBUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KanjiBooks/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             chunksize=chunksize)\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KanjiBooks/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KanjiBooks/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \"Execution failed on sql '{sql}': {exc}\".format(\n\u001b[1;32m   1444\u001b[0m                     sql=args[0], exc=exc))\n\u001b[0;32m-> 1445\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KanjiBooks/lib/python3.7/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;31m# this version of raise is a syntax error in Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/KanjiBooks/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT  timestamp,                        bval AS tempf,                        cval AS mesh_amps                        FROM kanji_eventlog WHERE node_id=20015 AND fcnt>0                        AND timestamp>NOW() - INTERVAL '18 HOURS'                        ORDER BY timestamp desc;': column \"bval\" does not exist\nLINE 1: SELECT  timestamp,                        bval AS tempf,    ...\n                                                  ^\n"
     ]
    }
   ],
   "source": [
    "#_LOG_LEVEL = _LOG_DEBUG\n",
    "_FIXED = True #False\n",
    "_PERIOD_HOURS = 18\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.geometry.polygon import Point, LinearRing\n",
    "import shapely.geometry as geometry\n",
    "import shapely.ops as so\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "_TMIN     = 20\n",
    "_TMAX     = 110\n",
    "\n",
    "# 5 Meshes are monitored, each with it's own parameters\n",
    "_TCRIT    = [78.0, 75.0, 88.0]\n",
    "_TIDLEBND = [6.0,   8.0,  4.0]\n",
    "\n",
    "_IMAX     = [20.0, 20.0, 20.0]\n",
    "_IBASE    = [2.0,   2.0,  2.0]\n",
    "_IBVAR    = [2.1,   2.1,  2.1] \n",
    "\n",
    "_INOM     = [5.0, 5.0, 5.0] \n",
    "_IVAR     = [2.0, 2.0, 2.0]\n",
    "\n",
    "_COLUMNS  = [\"cval\", \"dval\", \"eval\"]\n",
    "_MESHNAMES= [\"3&4\", \"5&6\", \"7&8\"]\n",
    "\n",
    "#which motes are sending CT_Profiler data\n",
    "motequery = \"SELECT node.idnode, node.name, location.description FROM kanji_node node \\\n",
    "             JOIN kanji_location location ON location.idlocation=node.location_id \\\n",
    "             WHERE nodetype_id={} AND deploystate_id={}\".format(CT_PROFILER_MOTE,DEPLOYED_ACTIVE)\n",
    "logger(_LOG_DEBUG, \"motequery={}\".format(motequery))\n",
    "\n",
    "motes = pd.read_sql(motequery, conn)\n",
    "if motes.size>0:\n",
    " for moteind in motes.index:\n",
    "  motename = motes['name'][moteind]\n",
    "  moteid = motes['idnode'][moteind]\n",
    "  courtesymessage = \"{}\\n\".format(motename)\n",
    "  motename = motes['name'][moteind]\n",
    "  motelocation = motes['description'][moteind]\n",
    "  logger(_LOG_INFO,\"\\nProcessing Cooling data for {} {}\".format(motelocation, motename))\n",
    "  for n in range(0,len(_COLUMNS)):\n",
    "       \n",
    "    #ctquery = \"SELECT  date_trunc('minute', timestamp) AS timestamp, \\\n",
    "    #                   avg(bval) AS tempf, \\\n",
    "    #                   avg({}) AS mesh_amps \\\n",
    "    #                   FROM kanji_eventlog WHERE node_id={} AND fcnt>0 \\\n",
    "    #                   AND timestamp>NOW() - INTERVAL '{} HOURS' \\\n",
    "    #                   GROUP BY date_trunc('minute', timestamp) \\\n",
    "    #                   ORDER BY date_trunc('minute', timestamp) desc;\".format(_COLUMNS[n], moteid, _PERIOD_HOURS)\n",
    "    ctquery = \"SELECT  timestamp, \\\n",
    "                       bval AS tempf, \\\n",
    "                       {} AS mesh_amps \\\n",
    "                       FROM kanji_eventlog WHERE node_id={} AND fcnt>0 \\\n",
    "                       AND timestamp>NOW() - INTERVAL '{} HOURS' \\\n",
    "                       ORDER BY timestamp desc;\".format(_COLUMNS[n], moteid, _PERIOD_HOURS)\n",
    "    logger(_LOG_DEBUG, ctquery)\n",
    "    df = pd.read_sql(ctquery, conn)    \n",
    "    \n",
    "    if df.size>0:\n",
    "      currenttemp = df['tempf'][0]\n",
    "      currentamps = df['mesh_amps'][0]\n",
    "      points = []\n",
    "      for ind in df.index:\n",
    "        temp = df['tempf'][ind]\n",
    "        amps = df['mesh_amps'][ind]        \n",
    "        points.append(Point(temp, amps)) \n",
    "      \n",
    "        \n",
    "      # these points define 4 non-overlapping polygons\n",
    "      if _FIXED==True:\n",
    "        p1  = Point(_TMIN,_IBASE[n]+_IBVAR[n])\n",
    "        p8  = Point(_TMIN,_IBASE[n]-_IBVAR[n])\n",
    "        p12 = Point(_TMIN,_IMAX[n])\n",
    "        p2  = Point(_TCRIT[n]-_TIDLEBND[n]/2,_IBASE[n]+_IBVAR[n])\n",
    "        p3  = Point(_TCRIT[n]-_TIDLEBND[n]/2,_INOM[n]+_IVAR[n])\n",
    "        p11 = Point(_TCRIT[n]-_TIDLEBND[n]/2,_IMAX[n])\n",
    "        p6  = Point(_TCRIT[n]+_TIDLEBND[n]/2,_INOM[n]-_IVAR[n])\n",
    "        p7  = Point(_TCRIT[n]+_TIDLEBND[n]/2,_IBASE[n]-_IBVAR[n])\n",
    "        p4  = Point(_TMAX,_INOM[n]+_IVAR[n])\n",
    "        p5  = Point(_TMAX,_INOM[n]-_IVAR[n])\n",
    "        p9  = Point(_TMAX,_IBASE[n]-_IBVAR[n])\n",
    "        p10 = Point(_TMAX,_IMAX[n])\n",
    "      else:\n",
    "        tstat = characterize(df)\n",
    "        print(_LOG_INFO,\"Tstat Characterize {}\".format(tstat))     \n",
    "        p1  = Point(_TMIN,tstat['avgoffamps']+_IBVAR[n])\n",
    "        p8  = Point(_TMIN,tstat['avgoffamps']-_IBVAR[n])\n",
    "        p12 = Point(_TMIN,_IMAX[n])\n",
    "        p2  = Point(tstat['setpoint']-tstat['idleband'],tstat['avgoffamps']+_IBVAR[n])\n",
    "        p3  = Point(tstat['setpoint']-tstat['idleband'],tstat['avgonamps']+_IVAR[n])\n",
    "        p11 = Point(tstat['setpoint']-tstat['idleband'],_IMAX[n])\n",
    "        p6  = Point(tstat['setpoint']+tstat['idleband'],tstat['avgonamps']-_IVAR[n])\n",
    "        p7  = Point(tstat['setpoint']+tstat['idleband'],tstat['avgoffamps']-_IBVAR[n])\n",
    "        p4  = Point(_TMAX,tstat['avgonamps']+_IVAR[n])\n",
    "        p5  = Point(_TMAX,tstat['avgonamps']-_IVAR[n])\n",
    "        p9  = Point(_TMAX,tstat['avgoffamps']-_IBVAR[n])\n",
    "        p10 = Point(_TMAX,_IMAX[n])\n",
    "\n",
    "      nominalring  = geometry.Polygon([p1,p2,p3,p4,p5,p6,p7,p8,p1])\n",
    "      x, y = nominalring.exterior.coords.xy\n",
    "\n",
    "      CODE_BLUE_ZONE =geometry.Polygon([p12,p11,p2,p1])\n",
    "      xi, yi = CODE_BLUE_ZONE.exterior.coords.xy\n",
    "\n",
    "      CODE_RED_ZONE = geometry.Polygon([p6,p5,p9,p7])\n",
    "      xii, yii = CODE_RED_ZONE.exterior.coords.xy\n",
    "\n",
    "      CODE_ORANGE_ZONE = geometry.Polygon([p11,p10,p4,p3])\n",
    "      xiii, yiii = CODE_ORANGE_ZONE.exterior.coords.xy\n",
    "  \n",
    "      #fig = plt.figure(1, figsize=(15,10), dpi=90)\n",
    "      fig, ax = plt.subplots(1, figsize=(15,10), dpi=90)\n",
    "      #ax = fig.add_subplot(111)\n",
    "      ring_patch = PolygonPatch(nominalring, fc='#40d93b', ec='#40d93b', fill=True, zorder=-1)\n",
    "      ax.add_patch(ring_patch)\n",
    "      ring_patch = PolygonPatch(CODE_BLUE_ZONE, fc='#014efe', ec='#014efe', fill=True, zorder=-1)\n",
    "      ax.add_patch(ring_patch)\n",
    "      ring_patch = PolygonPatch(CODE_RED_ZONE, fc='#fe0101', ec='#fe0101', fill=True, zorder=-1)\n",
    "      ax.add_patch(ring_patch)\n",
    "      ring_patch = PolygonPatch(CODE_ORANGE_ZONE, fc='#fe4801', ec='#fe4801', fill=True, zorder=-1)\n",
    "      ax.add_patch(ring_patch)\n",
    "      #ax.plot(x, y)\n",
    "      ax.set_title('Cooling Profile {} {}'.format(_COLUMNS[n], _MESHNAMES[n]))\n",
    "      xrange = [_TMIN, _TMAX]\n",
    "      yrange = [0, _IMAX[n]]\n",
    "      ax.set_xlim(*xrange)\n",
    "      ax.set_ylim(*yrange)\n",
    "      ax.set_aspect(1)  \n",
    "      \n",
    "      cpoint = []\n",
    "      currentpoint = Point(currenttemp,currentamps)\n",
    "      #print(currentpoint)\n",
    "      cpoint.append(Point(currenttemp, currentamps)) \n",
    "      xsc = [point.x for point in cpoint]\n",
    "      ysc = [point.y for point in cpoint]\n",
    "          \n",
    "      # scatter diagram for this period\n",
    "      xs = [point.x for point in points]\n",
    "      ys = [point.y for point in points]\n",
    "      plt.scatter(xs, ys, color='black')\n",
    "      plt.scatter(xsc, ysc, color='white')\n",
    "      \n",
    "      if currentpoint.within(nominalring):\n",
    "      #if nominalring.contains(currentpoint):\n",
    "        logger(_LOG_INFO, \"Latest {} measurement t={} A={} is nominal.\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        courtesymessage += \"   {} is nominal. T={:.1f}, A={:.1f}\\n\".format(_MESHNAMES[n], currenttemp, currentamps)\n",
    "      if currentpoint.within(CODE_BLUE_ZONE):\n",
    "        logger(_LOG_INFO, \"Latest {} measurement t={} A={} is CODE_BLUE\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        ticketIssue(conn, moteid, CODE_BLUE, \"CODE_BLUE Fans {} Temp={} Amps={}\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        postMessageToSlack(\"{} is CODE_BLUE alert.\".format(motelocation))\n",
    "      if currentpoint.within(CODE_RED_ZONE):\n",
    "        logger(_LOG_INFO, \"Latest {} measurement t={} A={} is CODE_RED\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        ticketIssue(conn, moteid, CODE_RED, \"CODE_RED Fans {} Temp={} Amps={}\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        postMessageToSlack(\"{} is CODE_RED alert.\".format(motelocation))\n",
    "      if currentpoint.within(CODE_ORANGE_ZONE):\n",
    "        logger(_LOG_INFO, \"Latest {} measurement t={} A={} is CODE_ORANGE\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        ticketIssue(conn, moteid, CODE_ORANGE, \"CODE_ORANGE Fans {} Temp={} Amps={}\".format(_MESHNAMES[n], currenttemp, currentamps))\n",
    "        postMessageToSlack(\"{} is CODE_ORANGE alert.\".format(motelocation))\n",
    "\n",
    "      #logger(_LOG_INFO, \"Latest measurement t={} A={}\".format(currenttemp, currentamps))  \n",
    "      if _LOG_LEVEL==_LOG_DEBUG:\n",
    "        print(nominalring)\n",
    "  #if len(courtesymessage)>0:\n",
    "  #  postMessageToSlack(courtesymessage)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KanjiProjects",
   "language": "python",
   "name": "kanjiprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
